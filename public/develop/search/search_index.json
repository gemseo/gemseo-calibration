{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#gemseo-calibration","title":"gemseo-calibration","text":""},{"location":"#overview","title":"Overview","text":"<p>Capability to calibrate GEMSEO disciplines from data.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install the latest version with <code>pip install gemseo-calibration</code>.</p> <p>See pip for more information.</p>"},{"location":"#bugs-and-questions","title":"Bugs and questions","text":"<p>Please use the gitlab issue tracker to submit bugs or questions.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>See the contributing section of GEMSEO.</p>"},{"location":"#contributors","title":"Contributors","text":"<ul> <li>Matthias De Lozzo</li> <li>Antoine DECHAUME</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes of this project will be documented here.</p> <p>The format is based on Keep a Changelog and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#develop","title":"Develop","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Calibrator   has a <code>formulation_settings_model</code> argument and keyword arguments <code>**formulation_settings</code>   (use either one or the other).</li> <li>CalibrationScenario   has a <code>formulation_settings_model</code> argument and keyword arguments <code>**formulation_settings</code>   (use either one or the other).</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>DataVersusModel   displays data on a grid.</li> <li>MultipleScatter   displays data on a grid.</li> <li>API CHANGES:<ul> <li><code>BaseCalibrationMetric.mesh</code> renamed to CalibrationMetricSettings.mesh_name.</li> <li>use the expression calibration metric rather the calibration measure,   to be consistent with gemseo.utils.metrics.</li> <li>rename <code>measures</code> package to metrics.</li> <li>rename <code>gemseo_calibration.measure.CalibrationMeasure</code> to gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric.</li> <li><code>gemseo_calibration.calibrator.CalibrationMeasure</code>:<ul> <li>rename it to gemseo_calibration.metrics.settings.CalibrationMetricSettings.</li> <li>CalibrationMetricSettings is a Pydantic model and so the arguments must be set as keyword arguments.</li> <li>move it to gemseo_calibration.metrics.settings.</li> <li>rename its field <code>measure</code> to <code>metric</code>.</li> <li>rename its field <code>mesh</code> to <code>mesh_name</code>.</li> <li>rename its field <code>output</code> to <code>output_name</code>.</li> </ul> </li> <li>rename <code>IntegratedMeasure</code> to BaseIntegratedMetric.</li> <li>rename <code>MeanMeasure</code> to BaseMeanMetric.</li> <li>Calibrator:<ul> <li>rename its <code>maximize_objective_measure</code> attribute to maximize_objective_metric.</li> <li>rename its <code>add_measure</code> method to add_metric.</li> <li>rename its <code>formulation</code> argument to <code>formulation_name</code></li> <li>rename its <code>control_outputs</code> argument to <code>metric_settings_models</code>.</li> </ul> </li> <li><code>CalibrationMeasureFactory</code>:<ul> <li>rename it to CalibrationMetricFactory.</li> <li>remove its <code>measures</code> property; use <code>class_names</code> instead.</li> <li>rename its method <code>is_integrated_measure</code> to is_integrated_metric.</li> </ul> </li> <li>remove the <code>formulation</code> argument of CalibrationScenario; use <code>formulation_name</code> instead.</li> <li>rename the <code>control_outputs</code> argument of CalibrationScenario to <code>metric_settings_models</code>.</li> </ul> </li> </ul>"},{"location":"changelog/#version-300-november-2024","title":"Version 3.0.0 (November 2024)","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Support GEMSEO v6.</li> <li>Support for Python 3.12.</li> </ul>"},{"location":"changelog/#version-202-december-2023","title":"Version 2.0.2 (December 2023)","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Support for Python 3.11.</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Support for Python 3.8.</li> </ul>"},{"location":"changelog/#version-201-september-2023","title":"Version 2.0.1 (September 2023)","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Compatibility with recent versions of NumPy.</li> </ul>"},{"location":"changelog/#version-200-june-2023","title":"Version 2.0.0 (June 2023)","text":"<ul> <li>Support GEMSEO v5.</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Data are <code>dict[str, ndarray]</code> objects a <code>{variable_name: variable_values}</code> instead of   Dataset.</li> <li>Use <code>\"\"</code> as empty value of <code>str</code> and <code>str | Path</code> arguments, instead of <code>\"None\"</code>.</li> <li>BaseCalibrationMetric:   the type of <code>f_type</code> is FunctionType.</li> </ul>"},{"location":"changelog/#version-100-july-2022","title":"Version 1.0.0 (July 2022)","text":"<p>First release.</p>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#exec-1--credits","title":"Credits","text":"<p>The developers thank all the open source libraries making <code>gemseo-calibration</code> possible.</p>"},{"location":"credits/#exec-1--external-dependencies","title":"External Dependencies","text":"<p><code>gemseo-calibration</code> depends on software with compatible licenses that are listed below.</p> Project License <code>Python</code> Python Software License <code>gemseo</code> GNU Lesser General Public License v3 <code>matplotlib</code> Python Software Foundation License <code>numpy</code> BSD License"},{"location":"credits/#exec-1--external-applications","title":"External applications","text":"<p>Some external applications are used by <code>gemseo-calibration</code>, but not linked with the application, for testing, documentation generation, training or example purposes.</p> Project License <code>black</code> MIT <code>commitizen</code> MIT License <code>covdefaults</code> MIT License <code>griffe-fieldz</code> BSD-3-Clause <code>griffe-inherited-docstrings</code> ISC <code>insert-license</code> MIT <code>markdown-exec</code> ISC <code>mike</code> BSD-3-Clause <code>mkdocs-bibtex</code> BSD-3-Clause-LBNL <code>mkdocs-gallery</code> BSD 3-Clause <code>mkdocs-gen-files</code> MIT License <code>mkdocs-include-markdown-plugin</code> Apache-2.0 <code>mkdocs-literate-nav</code> MIT License <code>mkdocs-material</code> MIT License <code>mkdocs-section-index</code> MIT License <code>mkdocstrings</code> ISC <code>pre-commit</code> MIT License <code>pygrep-hooks</code> MIT <code>pytest</code> MIT License <code>pytest-cov</code> MIT License <code>pytest-xdist</code> MIT License <code>ruff</code> MIT License <code>setuptools</code> MIT License <code>setuptools-scm</code> MIT License"},{"location":"licenses/","title":"Licenses","text":""},{"location":"licenses/#licenses","title":"Licenses","text":""},{"location":"licenses/#gnu-lgpl-v30","title":"GNU LGPL v3.0","text":"<p>The <code>gemseo-calibration</code> source code is distributed under the GNU LGPL v3.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis program is free software; you can redistribute it and/or\nmodify it under the terms of the GNU Lesser General Public\nLicense version 3 as published by the Free Software Foundation.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\nLesser General Public License for more details.\n\nYou should have received a copy of the GNU Lesser General Public License\nalong with this program; if not, write to the Free Software Foundation,\nInc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n</code></pre></p>"},{"location":"licenses/#bsd-0-clause","title":"BSD 0-Clause","text":"<p>The <code>gemseo-calibration</code> examples are distributed under the BSD 0-Clause <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under a BSD 0-Clause License.\n\nPermission to use, copy, modify, and/or distribute this software\nfor any purpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL\nWARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED\nWARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\nTHE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT,\nOR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\nFROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\nNEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\nWITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n</code></pre></p>"},{"location":"licenses/#cc-by-sa-40","title":"CC BY-SA 4.0","text":"<p>The <code>gemseo-calibration</code> documentation is distributed under the CC BY-SA 4.0 license. <pre><code>Copyright 2021 IRT Saint Exup\u00e9ry, https://www.irt-saintexupery.com\n\nThis work is licensed under the Creative Commons Attribution-ShareAlike 4.0\nInternational License. To view a copy of this license, visit\nhttp://creativecommons.org/licenses/by-sa/4.0/ or send a letter to Creative\nCommons, PO Box 1866, Mountain View, CA 94042, USA.\n</code></pre></p>"},{"location":"generated/examples/calibration/","title":"Examples","text":""},{"location":"generated/examples/calibration/#calibration","title":"Calibration","text":"<p>Update the parameters of a discipline from data.</p> <p> Observations with missing values. </p> <p> One calibration parameter. </p> <p> Disciplinary chain. </p> <p> Constrained calibration. </p> <p> Two calibration parameters. </p> <p> Strongly coupled models. </p> <p> Functional output discretized on a mesh. </p> <p> Noisy observations. </p> <p> Download all examples in Python source code: calibration_python.zip</p> <p> Download all examples in Jupyter notebooks: calibration_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/mg_execution_times/","title":"Computation times","text":"<p>00:24.318 total execution time for generated_examples_calibration files:</p> <p>+----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_missing_values (docs/examples/calibration/plot_missing_values.py) | 00:08.264 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_mda (docs/examples/calibration/plot_mda.py)                                  | 00:03.097 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_constraint (docs/examples/calibration/plot_constraint.py)             | 00:02.692 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_noise (docs/examples/calibration/plot_noise.py)                            | 00:02.600 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_chain (docs/examples/calibration/plot_chain.py)                            | 00:02.214 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_mesh (docs/examples/calibration/plot_mesh.py)                               | 00:02.183 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_two_parameters (docs/examples/calibration/plot_two_parameters.py) | 00:01.916 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+ | plot_one_parameter (docs/examples/calibration/plot_one_parameter.py)    | 00:01.352 | 0.0 MB | +----------------------------------------------------------------------------------------------------+-----------+--------+</p>"},{"location":"generated/examples/calibration/plot_chain/","title":"Disciplinary chain.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_chain/#disciplinary-chain","title":"Disciplinary chain.","text":"<p>This example illustrates the calibration of a chain of disciplines with two poorly known parameters.</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import sample_disciplines\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom numpy import array\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n</code></pre> <p>Let us consider a model \\(f(x)=ax+b\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}\\), decomposed into two disciplines:</p> <pre><code>models = [\n    AnalyticDiscipline({\"y\": \"ax+b\"}, name=\"model_2\"),\n    AnalyticDiscipline({\"ax\": \"a*x\"}, name=\"model_1\"),\n]\n</code></pre> <p>Note</p> <p>The disciplines are deliberately placed out of order, to illustrate the fact that by default, the CalibrationScenario uses the MDF formulation to analyse the couplings and execute the disciplines in the right order.</p> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>reference = AnalyticDiscipline({\"y\": \"2*x+3\"}, name=\"reference\")\n</code></pre> <p>However in this pedagogical example, the mathematical relationship is known, and we can see that the parameters \\(a\\) and \\(b\\) must be equal to 2 and 3 respectively so that the model and the reference are identical.</p> <p>In the following, we will try to find this value from a unique observation.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\([a,b]\\in[0,10]^2\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=0.0, upper_bound=10.0, value=0.0)\nprior.add_variable(\"b\", lower_bound=0.0, upper_bound=10.0, value=0.0)\n</code></pre> <p>Secondly, given an input space \\([0,3]\\):</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0)\n</code></pre> <p>we generate reference output data by sampling the reference discipline:</p> <pre><code>reference_dataset = sample_disciplines(\n    [reference],\n    input_space,\n    [\"y\"],\n    algo_name=\"CustomDOE\",\n    samples=array([[1.0], [2.0]]),\n)\nreference_data = reference_dataset.to_dict_of_arrays(False)\n</code></pre> <p>From this unique observation, we can build and execute a CalibrationScenario to find the value of the parameters \\(a\\) and \\(b\\) which minimizes a CalibrationMetric taking into account the output \\(y\\):</p> <pre><code>calibration = CalibrationScenario(\n    models, \"x\", CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"), prior\n)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can check that the calibrated parameters are very close to the expected ones</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([2.01769919, 2.97263066])\n</code></pre> <p>and plot an optimization history view:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c922540ac10&gt;\n</code></pre> <p>as well as the model data versus the reference ones, before and after the calibration:</p> <pre><code>calibration.post_process(post_name=\"DataVersusModel\", output=\"y\", save=False, show=True)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;gemseo_calibration.post.data_versus_model.post.DataVersusModel object at 0x7c92221c7c10&gt;\n</code></pre> <p>Total running time of the script: ( 0 minutes  2.214 seconds)</p> <p> Download Python source code: plot_chain.py</p> <p> Download Jupyter notebook: plot_chain.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_constraint/","title":"Constrained calibration.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_constraint/#constrained-calibration","title":"Constrained calibration.","text":"<p>This example illustrates the calibration of a discipline with two poorly known parameters and a constraint.</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import sample_disciplines\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom numpy import array\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n</code></pre> <p>Let us consider a model \\(f(x)=[ax,bx]\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}^2\\):</p> <pre><code>model = AnalyticDiscipline({\"y\": \"a*x\", \"z\": \"b*x\"}, name=\"model\")\n</code></pre> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>reference = AnalyticDiscipline({\"y\": \"2*x\", \"z\": \"3*x\"}, name=\"reference\")\n</code></pre> <p>However in this pedagogical example, the mathematical relationship is known, and we can see that the parameters \\(a\\) and \\(b\\) must be equal to 2 and 3 respectively so that the model and the reference are identical.</p> <p>In the following, we will try to find these values from several information sources.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\([a,b]\\in[0,10]^2\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=0.0, upper_bound=10.0, value=0.0)\nprior.add_variable(\"b\", lower_bound=0.0, upper_bound=10.0, value=0.0)\n</code></pre> <p>Secondly, given an input space \\([0,3]\\):</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0)\n</code></pre> <p>we generate reference output data by sampling the reference discipline:</p> <pre><code>reference_dataset = sample_disciplines(\n    [reference],\n    input_space,\n    [\"y\", \"z\"],\n    algo_name=\"CustomDOE\",\n    samples=array([[1.0], [2.0]]),\n)\nreference_data = reference_dataset.to_dict_of_arrays(False)\n</code></pre> <p>From these information sources, we can build and execute a CalibrationScenario to find the values of the parameters \\(a\\) and \\(b\\) which minimize a BaseCalibrationMetric related to the output \\(y\\) with a constraint about a BaseCalibrationMetric related to the output \\(z\\).</p> <pre><code>calibration = CalibrationScenario(\n    model, \"x\", CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"), prior\n)\ncalibration.add_constraint(\n    CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")\n)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can check that the calibrated parameters are very close to the expected ones:</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([1.99999999, 2.99999999])\n</code></pre> <p>and plot an optimization history view:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c922230cf40&gt;\n</code></pre> <p>as well as the model data versus the reference ones, before and after the calibration:</p> <pre><code>calibration.post_process(post_name=\"DataVersusModel\", output=\"z\", save=False, show=True)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;gemseo_calibration.post.data_versus_model.post.DataVersusModel object at 0x7c9221ebcbe0&gt;\n</code></pre> <p>Total running time of the script: ( 0 minutes  2.692 seconds)</p> <p> Download Python source code: plot_constraint.py</p> <p> Download Jupyter notebook: plot_constraint.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_mda/","title":"Strongly coupled models.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_mda/#strongly-coupled-models","title":"Strongly coupled models.","text":"<p>This example illustrates the calibration of a system of strongly coupled disciplines with two poorly known parameters.</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import sample_disciplines\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom numpy import array\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n</code></pre> <p>Let us consider a model \\(f(x)\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}^2\\), decomposed into a model \\(f_1(x,y_2)=x+ay_2\\) from \\(\\mathbb{R}^2\\) to \\(\\mathbb{R}\\):</p> <pre><code>model_1 = AnalyticDiscipline({\"y1\": \"x+a*y2\"}, name=\"model_1\")\n</code></pre> <p>and a model \\(f_2(x,y_1)=x+by_1\\) from \\(\\mathbb{R}^2\\) to \\(\\mathbb{R}\\):</p> <pre><code>model_2 = AnalyticDiscipline({\"y2\": \"x+b*y1\"}, name=\"model_2\")\nmodels = [model_1, model_2]\n</code></pre> <p>such that \\(f(x)=(y_1,y_2).\\)</p> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>reference = AnalyticDiscipline({\"y1\": \"x+2*y2\", \"y2\": \"x+3*y1\"}, name=\"reference\")\n</code></pre> <p>However in this pedagogical example, the mathematical relationship is known, and we can see that the parameters \\(a\\) and \\(b\\) must be equal to 2 and 3 respectively so that the model and the reference are identical.</p> <p>In the following, we will try to find this value from a unique observation.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\([a,b]\\in[1,10]^2\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=1.0, upper_bound=10.0, value=1.0)\nprior.add_variable(\"b\", lower_bound=1.0, upper_bound=10.0, value=1.0)\n</code></pre> <p>Secondly, given an input space \\([0,3]\\):</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0)\n</code></pre> <p>we generate reference output data by sampling the reference discipline:</p> <pre><code>reference_dataset = sample_disciplines(\n    [reference],\n    input_space,\n    [\"y1\", \"y2\"],\n    algo_name=\"CustomDOE\",\n    samples=array([[1.0], [2.0]]),\n)\nreference_data = reference_dataset.to_dict_of_arrays(False)\n</code></pre> <p>From this unique observation, we can build and execute a CalibrationScenario to find the value of the parameters \\(a\\) and \\(b\\) which minimizes CalibrationMetric taking into account the outputs \\(y_1\\) and \\(y_2\\):</p> <pre><code>calibration = CalibrationScenario(\n    models,\n    \"x\",\n    [\n        CalibrationMetricSettings(output_name=\"y1\", metric_name=\"MSE\"),\n        CalibrationMetricSettings(output_name=\"y2\", metric_name=\"MSE\"),\n    ],\n    prior,\n)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can check that the calibrated parameters are very close to the expected ones</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([2.02528232, 2.94410871])\n</code></pre> <p>and plot an optimization history view:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c9221e173d0&gt;\n</code></pre> <p>as well as the model data versus the reference ones, before and after the calibration:</p> <pre><code>calibration.post_process(\n    post_name=\"DataVersusModel\", output=\"y1\", save=False, show=True\n)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;gemseo_calibration.post.data_versus_model.post.DataVersusModel object at 0x7c92249918e0&gt;\n</code></pre> <p>Total running time of the script: ( 0 minutes  3.097 seconds)</p> <p> Download Python source code: plot_mda.py</p> <p> Download Jupyter notebook: plot_mda.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_mesh/","title":"Functional output discretized on a mesh.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_mesh/#functional-output-discretized-on-a-mesh","title":"Functional output discretized on a mesh.","text":"<p>This example illustrates the calibration of a discipline with two poorly known parameters and a functional output discretized on a mesh.</p> <pre><code>from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom gemseo import sample_disciplines\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.core.discipline.discipline import Discipline\nfrom numpy import array\nfrom numpy import linspace\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n\nif TYPE_CHECKING:\n    from gemseo.typing import StrKeyMapping\n</code></pre> <p>Let us consider a model \\(f(x)=[ax,\\gamma bx, \\gamma]\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}^{11}\\) where \\(\\gamma=[0,0.25,0.5,0.75,1.]\\) plays the role of a mesh. In practice, we could imagine a model having an output related to a mesh \\(\\gamma\\) whose size and nodes would depend on the model inputs. Thus, this mesh is also an output of the model.</p> <pre><code>class Model(Discipline):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.input_grammar.update_from_names([\"x\", \"a\", \"b\"])\n        self.output_grammar.update_from_names([\"y\", \"z\", \"mesh\"])\n        self.default_input_data = {\n            \"x\": array([0.0]),\n            \"a\": array([0.0]),\n            \"b\": array([0.0]),\n        }\n\n    def _run(self, input_data: StrKeyMapping) -&gt; StrKeyMapping | None:\n        x_input = input_data[\"x\"]\n        a_parameter = input_data[\"a\"]\n        b_parameter = input_data[\"b\"]\n        y_output = a_parameter * x_input\n        z_mesh = linspace(0, 1, 5)\n        z_output = b_parameter * x_input[0] * z_mesh\n        return {\"y\": y_output, \"z\": z_output, \"mesh\": z_mesh}\n</code></pre> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>class ReferenceModel(Discipline):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.input_grammar.update_from_names([\"x\"])\n        self.output_grammar.update_from_names([\"y\", \"z\", \"mesh\"])\n        self.default_input_data = {\"x\": array([0.0])}\n\n    def _run(self, input_data: StrKeyMapping) -&gt; StrKeyMapping | None:\n        x_input = input_data[\"x\"]\n        y_output = 2 * x_input\n        z_mesh = linspace(0, 1, 5)\n        z_output = 3 * x_input[0] * z_mesh\n        return {\"y\": y_output, \"z\": z_output, \"mesh\": z_mesh}\n</code></pre> <p>However in this pedagogical example, the mathematical relationship is known, and we can see that the parameters \\(a\\) and \\(b\\) must be equal to 2 and 3 respectively so that the model and the reference are identical.</p> <p>In the following, we will try to find these values from several information sources.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\([a,b]\\in[0,10]^2\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=0.0, upper_bound=10.0, value=0.0)\nprior.add_variable(\"b\", lower_bound=0.0, upper_bound=10.0, value=0.0)\n</code></pre> <p>Secondly, given an input space \\([0,3]\\):</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0)\n</code></pre> <p>we generate reference output data by sampling the reference discipline:</p> <pre><code>reference = ReferenceModel()\nreference_dataset = sample_disciplines(\n    [reference],\n    input_space,\n    [\"mesh\", \"y\", \"z\"],\n    algo_name=\"CustomDOE\",\n    samples=array([[1.0], [2.0]]),\n)\nreference_data = reference_dataset.to_dict_of_arrays(False)\n</code></pre> <p>From these information sources, we can build and execute a CalibrationScenario to find the values of the parameters \\(a\\) and \\(b\\) which minimize a BaseCalibrationMetric taking into account the outputs \\(y\\) and \\(z\\):</p> <pre><code>model = Model()\nmetric_settings = [\n    CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"),\n    CalibrationMetricSettings(output_name=\"z\", metric_name=\"ISE\", mesh_name=\"mesh\"),\n]\ncalibration = CalibrationScenario(model, \"x\", metric_settings, prior)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can check that the calibrated parameters are very close to the expected ones:</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([1.99999998, 2.99999998])\n</code></pre> <p>and plot an optimization history view:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c922236bb20&gt;\n</code></pre> <p>as well as the model data versus the reference ones, before and after the calibration:</p> <pre><code>calibration.post_process(post_name=\"DataVersusModel\", output=\"y\", save=False, show=True)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;gemseo_calibration.post.data_versus_model.post.DataVersusModel object at 0x7c9222327a00&gt;\n</code></pre> <p>Total running time of the script: ( 0 minutes  2.183 seconds)</p> <p> Download Python source code: plot_mesh.py</p> <p> Download Jupyter notebook: plot_mesh.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_missing_values/","title":"Observations with missing values.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_missing_values/#observations-with-missing-values","title":"Observations with missing values.","text":"<p>This example illustrates the calibration of a discipline with two poorly known parameters and from observations with missing values.</p> <p>Out:</p> <pre><code>&lt;frozen importlib._bootstrap&gt;:228: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n&lt;frozen importlib._bootstrap&gt;:228: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n&lt;frozen importlib._bootstrap&gt;:228: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n/builds/gemseo/dev/gemseo-calibration/.tox/doc/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n  backends.update(_get_backends(\"networkx.backends\"))\n</code></pre> <p></p> <pre><code>from __future__ import annotations\n\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.datasets.dataset import Dataset\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom numpy import array\nfrom numpy import nan\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n\nmodel = AnalyticDiscipline({\"y\": \"a*x\", \"z\": \"b*x\"}, name=\"model\")\n\nprior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=0.0, upper_bound=10.0, value=0.0)\nprior.add_variable(\"b\", lower_bound=0.0, upper_bound=10.0, value=0.0)\n\ndata = array([\n    [1, 1.0, 2.0, nan],\n    [2, 1.0, nan, 3.0],\n    [3, 2.0, 4.0, nan],\n    [4, 2.0, nan, 6.0],\n])\nreference_data = Dataset.from_array(\n    data,\n    variable_names=[\"index\", \"x\", \"y\", \"z\"],\n    variable_names_to_group_names={\n        \"index\": \"inputs\",\n        \"x\": \"inputs\",\n        \"y\": \"outputs\",\n        \"z\": \"outputs\",\n    },\n).to_dict_of_arrays(False)\n\nmetric_settings = [\n    CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"),\n    CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\"),\n]\ncalibration = CalibrationScenario(model, \"x\", metric_settings, prior)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Total running time of the script: ( 0 minutes  8.264 seconds)</p> <p> Download Python source code: plot_missing_values.py</p> <p> Download Jupyter notebook: plot_missing_values.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_noise/","title":"Noisy observations.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_noise/#noisy-observations","title":"Noisy observations.","text":"<p>This example illustrates the calibration of a discipline with three poorly known parameters and from noisy observations.</p> <pre><code>from __future__ import annotations\n</code></pre> <p>Let us consider a model \\(f(x)=ax^2+bx+c\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}\\):</p> <pre><code>from gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.core.chains.chain import MDOChain\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom gemseo.disciplines.scenario_adapters.mdo_scenario_adapter import MDOScenarioAdapter\nfrom gemseo.scenarios.doe_scenario import DOEScenario\nfrom matplotlib import pyplot as plt\nfrom numpy import array\nfrom numpy import linspace\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n\nmodel = AnalyticDiscipline({\"y\": \"a*x**2+b*x+c\"}, name=\"model\")\n</code></pre> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>original_model = AnalyticDiscipline({\"y\": \"2*x**2-1.5*x+0.75\"}, name=\"model\")\n\nreference = MDOChain([original_model, AnalyticDiscipline({\"y\": \"y+u\"}, name=\"noise\")])\nreference.set_cache(reference.CacheType.MEMORY_FULL)\n</code></pre> <p>This reference model contains a random additive term \\(u\\) normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\). This means that the observations of \\(f:x\\mapsto 2x^2-1.5x+0.75\\) are noised.</p> <p>In this pedagogical example, the mathematical relationship is known, and we can see that the parameters \\(a\\), \\(b\\) and \\(c\\) must be equal to 2, 0.5 and 0.75 respectively so that the model and the reference are identical.</p> <p>In the following, we will try to find these values from several information sources.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\([a,b,c]\\in[-5,5]^2\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=-5.0, upper_bound=5.0, value=0.0)\nprior.add_variable(\"b\", lower_bound=-5.0, upper_bound=5.0, value=0.0)\nprior.add_variable(\"c\", lower_bound=-5.0, upper_bound=5.0, value=0.0)\n</code></pre> <p>Secondly, we have reference output data over the input space \\([0,3]\\).</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0, value=1.5)\n</code></pre> <p>These data are noisy; this noise can be modeled by a centered Gaussian random variable with standard deviation equal to 0.5.</p> <pre><code>noise_space = ParameterSpace()\nnoise_space.add_random_variable(\"u\", \"OTNormalDistribution\", mu=0.0, sigma=0.5)\n</code></pre> <p>Out:</p> <pre><code>/builds/gemseo/dev/gemseo-calibration/.tox/doc/lib64/python3.9/site-packages/pydantic/main.py:209: DeprecationWarning: Conversion of an array with ndim &gt; 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n</code></pre> <p>The observations can be generated with two nested design of experiments: an inner one sampling the reference model \\(f\\), an outer one repeating this sampling for different values of the noise. A classical way of doing this with |g| is to use a MDOScenarioAdapter which is a Discipline executing a DOEScenario for a given value of \\(u\\). For example, let us imagine a DOEScenario evaluating the reference data source at 5 equispaced points \\(x_1,\\ldots,x_5\\).</p> <pre><code>sub_scenario = DOEScenario(\n    [reference], \"y\", input_space, formulation_name=\"DisciplinaryOpt\"\n)\nsub_scenario.set_algorithm(algo_name=\"PYDOE_FULLFACT\", n_samples=5)\n\nadapter = MDOScenarioAdapter(sub_scenario, [\"u\"], [\"y\"])\n</code></pre> <p>Then, this MDOScenarioAdapter is embedded in a DOEScenario in charge to sample it over the uncertain space.</p> <pre><code>scenario = DOEScenario([adapter], \"y\", noise_space, formulation_name=\"DisciplinaryOpt\")\nscenario.execute(algo_name=\"OT_LHSC\", n_samples=5)\nreference_data = reference.cache.to_dataset().to_dict_of_arrays(False)\n</code></pre> <p>From these information sources, we can build and execute a CalibrationScenario to find the values of the parameters \\(a\\), \\(b\\) and \\(c\\) which minimize a BaseCalibrationMetric related to the output \\(y\\):</p> <pre><code>calibration = CalibrationScenario(\n    model, \"x\", CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"), prior\n)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can see that the calibrated parameters are different from the expected ones</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([ 1.70873836, -0.51281766,  0.21239429])\n</code></pre> <p>even if the result are converged:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c922278ca30&gt;\n</code></pre> <p>However, the calibrated model is close the expected one:</p> <pre><code>expression = \"a*x**2+b*x+c\"\nfor parameter_name, parameter_value in calibration.posterior_parameters.items():\n    expression = expression.replace(parameter_name, str(parameter_value[0]))\ncalibrated = AnalyticDiscipline({\"y\": expression}, name=\"calibrated\")\n\nx_values = linspace(0.0, 3.0, 100)\ny_values = [original_model.execute({\"x\": array([x_i])})[\"y\"][0] for x_i in x_values]\npost_y_values = [calibrated.execute({\"x\": array([x_i])})[\"y\"][0] for x_i in x_values]\nplt.plot(x_values, y_values, color=\"blue\", label=\"Unknown model\")\nplt.plot(x_values, post_y_values, color=\"red\", label=\"Calibrated model\")\n\nx_points = []\ny_points = []\nfor data in reference.cache:\n    x_points.append(data.inputs[\"x\"][0])\n    y_points.append(data.outputs[\"y\"][0])\n\nplt.plot(\n    x_points,\n    y_points,\n    color=\"blue\",\n    linestyle=\"\",\n    marker=\"x\",\n    label=\"Reference data\",\n)\nplt.legend()\nplt.show()\n</code></pre> <p></p> <p>Total running time of the script: ( 0 minutes  2.600 seconds)</p> <p> Download Python source code: plot_noise.py</p> <p> Download Jupyter notebook: plot_noise.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_one_parameter/","title":"One calibration parameter.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_one_parameter/#one-calibration-parameter","title":"One calibration parameter.","text":"<p>This example illustrates the calibration of a discipline with a poorly known parameter.</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import sample_disciplines\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom numpy import array\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n</code></pre> <p>Let us consider a function \\(f(x)=ax\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}\\):</p> <pre><code>model = AnalyticDiscipline({\"y\": \"a*x\"}, name=\"model\")\n</code></pre> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>reference = AnalyticDiscipline({\"y\": \"2*x\"}, name=\"reference\")\n</code></pre> <p>However in this pedagogical example, the mathematical relationship is known, and we can see that the parameter \\(a\\) must be equal to 2 so that the model and the reference are identical.</p> <p>In the following, we will try to find this value from a unique observation.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\(a\\in[0,10]\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=0.0, upper_bound=10.0, value=0.0)\n</code></pre> <p>Secondly, given an input space \\([0,3]\\):</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0)\n</code></pre> <p>we generate reference output data by sampling the reference discipline:</p> <pre><code>reference_dataset = sample_disciplines(\n    [reference], input_space, [\"y\"], algo_name=\"CustomDOE\", samples=array([[1.0]])\n)\nreference_data = reference_dataset.to_dict_of_arrays(False)\n</code></pre> <p>From this unique observation, we can build and execute a CalibrationScenario to find the value of the parameter \\(a\\) which minimizes a BaseCalibrationMetric taking into account the output \\(y\\):</p> <pre><code>calibration = CalibrationScenario(\n    model, \"x\", CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"), prior\n)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can check that the calibrated parameter is very close to the expected one:</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([1.99999999])\n</code></pre> <p>and plot an optimization history view:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c9224da1640&gt;\n</code></pre> <p>as well as the model data versus the reference ones, before and after the calibration:</p> <pre><code>calibration.post_process(post_name=\"DataVersusModel\", output=\"y\", save=False, show=True)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;gemseo_calibration.post.data_versus_model.post.DataVersusModel object at 0x7c92263abe50&gt;\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.352 seconds)</p> <p> Download Python source code: plot_one_parameter.py</p> <p> Download Jupyter notebook: plot_one_parameter.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/examples/calibration/plot_two_parameters/","title":"Two calibration parameters.","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/examples/calibration/plot_two_parameters/#two-calibration-parameters","title":"Two calibration parameters.","text":"<p>This example illustrates the calibration of a discipline with two poorly known parameters.</p> <pre><code>from __future__ import annotations\n\nfrom gemseo import sample_disciplines\nfrom gemseo.algos.design_space import DesignSpace\nfrom gemseo.algos.parameter_space import ParameterSpace\nfrom gemseo.disciplines.analytic import AnalyticDiscipline\nfrom numpy import array\n\nfrom gemseo_calibration.metrics.settings import CalibrationMetricSettings\nfrom gemseo_calibration.scenario import CalibrationScenario\n</code></pre> <p>Let us consider a model \\(f(x)=[ax,bx]\\) from \\(\\mathbb{R}\\) to \\(\\mathbb{R}^2\\):</p> <pre><code>model = AnalyticDiscipline({\"y\": \"a*x\", \"z\": \"b*x\"}, name=\"model\")\n</code></pre> <p>This is a model of our reference data source, which is a kind of oracle providing input-output data without the mathematical relationship behind it:</p> <pre><code>reference = AnalyticDiscipline({\"y\": \"2*x\", \"z\": \"3*x\"}, name=\"reference\")\n</code></pre> <p>However in this pedagogical example, the mathematical relationship is known, and we can see that the parameters \\(a\\) and \\(b\\) must be equal to 2 and 3 respectively so that the model and the reference are identical.</p> <p>In the following, we will try to find these values from several information sources.</p> <p>Firstly, we have prior knowledge of the parameter values, that is \\([a,b]\\in[0,10]^2\\):</p> <pre><code>prior = ParameterSpace()\nprior.add_variable(\"a\", lower_bound=0.0, upper_bound=10.0, value=0.0)\nprior.add_variable(\"b\", lower_bound=0.0, upper_bound=10.0, value=0.0)\n</code></pre> <p>Secondly, given an input space \\([0,3]\\):</p> <pre><code>input_space = DesignSpace()\ninput_space.add_variable(\"x\", lower_bound=0.0, upper_bound=3.0)\n</code></pre> <p>we generate reference output data by sampling the reference discipline:</p> <pre><code>reference_dataset = sample_disciplines(\n    [reference],\n    input_space,\n    [\"y\", \"z\"],\n    algo_name=\"CustomDOE\",\n    samples=array([[1.0], [2.0]]),\n)\nreference_data = reference_dataset.to_dict_of_arrays(False)\n</code></pre> <p>From these information sources, we can build and execute a CalibrationScenario to find the values of the parameters \\(a\\) and \\(b\\) which minimize a BaseCalibrationMetric taking into account the outputs \\(y\\) and \\(z\\):</p> <pre><code>metric_settings = [\n    CalibrationMetricSettings(output_name=\"y\", metric_name=\"MSE\"),\n    CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\"),\n]\ncalibration = CalibrationScenario(model, \"x\", metric_settings, prior)\ncalibration.execute(\n    algo_name=\"NLOPT_COBYLA\", reference_data=reference_data, max_iter=100\n)\n</code></pre> <p>Lastly, we can check that the calibrated parameters are very close to the expected ones:</p> <pre><code>calibration.optimization_result.x_opt\n</code></pre> <p>Out:</p> <pre><code>array([1.99999995, 2.99999996])\n</code></pre> <p>and plot an optimization history view:</p> <pre><code>calibration.post_process(post_name=\"OptHistoryView\", save=False, show=True)\n</code></pre> <p>Out:</p> <pre><code>&lt;gemseo.post.opt_history_view.OptHistoryView object at 0x7c92227b1880&gt;\n</code></pre> <p>as well as the model data versus the reference ones, before and after the calibration:</p> <pre><code>calibration.post_process(post_name=\"DataVersusModel\", output=\"z\", save=False, show=True)\n</code></pre> <p></p> <p>Out:</p> <pre><code>&lt;gemseo_calibration.post.data_versus_model.post.DataVersusModel object at 0x7c92221c72e0&gt;\n</code></pre> <p>Total running time of the script: ( 0 minutes  1.916 seconds)</p> <p> Download Python source code: plot_two_parameters.py</p> <p> Download Jupyter notebook: plot_two_parameters.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>gemseo_calibration<ul> <li>calibrator</li> <li>metrics<ul> <li>base_calibration_metric</li> <li>base_integrated_metric</li> <li>base_mean_metric</li> <li>factory</li> <li>iae</li> <li>ise</li> <li>mae</li> <li>mse</li> <li>settings</li> </ul> </li> <li>post<ul> <li>data_versus_model<ul> <li>post</li> <li>settings</li> </ul> </li> <li>factory</li> <li>multiple_scatter</li> </ul> </li> <li>post_processor</li> <li>scenario</li> </ul> </li> </ul>"},{"location":"reference/gemseo_calibration/","title":"API documentation","text":""},{"location":"reference/gemseo_calibration/#gemseo_calibration","title":"gemseo_calibration","text":"<p>A package to calibrate a multidisciplinary system from reference data.</p>"},{"location":"reference/gemseo_calibration/calibrator/","title":"Calibrator","text":""},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator","title":"calibrator","text":"<p>A discipline evaluating the quality of another one with respect to reference data.</p>"},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator","title":"Calibrator","text":"<pre><code>Calibrator(\n    disciplines: Discipline | list[Discipline],\n    input_names: str | Iterable[str],\n    metric_settings_models: (\n        CalibrationMetricSettings\n        | Sequence[CalibrationMetricSettings]\n    ),\n    parameter_names: str | Iterable[str],\n    formulation_settings_model: (\n        BaseFormulationSettings | None\n    ) = None,\n    **formulation_settings: Any\n)\n</code></pre> <p>               Bases: <code>MDOScenarioAdapter</code></p> <p>A discipline with parameters calibrated from reference input-output data.</p> <p>When it is executed from parameters values, it computes the calibration metric with respect to the reference data, provided through the set_reference_data method.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Discipline | list[Discipline]</code>)           \u2013            <p>The disciplines whose parameters must be calibrated from the reference data.</p> </li> <li> <code>input_names</code>               (<code>str | Iterable[str]</code>)           \u2013            <p>The names of the inputs to be considered for the calibration.</p> </li> <li> <code>metric_settings_models</code>               (<code>CalibrationMetricSettings | Sequence[CalibrationMetricSettings]</code>)           \u2013            <p>A collection of calibration settings, including the name of the observed output, the name of the calibration metric and the corresponding weight comprised between 0 and 1 (the weights must sum to 1). When the output is a 1D function discretized over a mesh, the name of the mesh can be provided. E.g. <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")</code> <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)</code> or <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")</code> Lastly, <code>CalibrationMetric</code> can be imported from gemseo_calibration.calibrator.</p> </li> <li> <code>parameter_names</code>               (<code>str | Iterable[str]</code>)           \u2013            <p>The names of the parameters to be calibrated.</p> </li> <li> <code>formulation_settings_model</code>               (<code>BaseFormulationSettings | None</code>, default:                   <code>None</code> )           \u2013            <p>The MDO formulation settings as a Pydantic model. If <code>None</code>, use <code>**settings</code>.</p> </li> <li> <code>**formulation_settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The MDO formulation settings, including the formulation name (use the keyword <code>\"formulation_name\"</code>). These arguments are ignored when <code>settings_model</code> is not <code>None</code>. If none and <code>settings_model</code> is <code>None</code>, the calibrator uses the default MDF formulation.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If both <code>reset_x0_before_opt</code> and <code>set_x0_before_opt</code> are True.</p> </li> </ul> Source code in <code>src/gemseo_calibration/calibrator.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Discipline | list[Discipline],\n    input_names: str | Iterable[str],\n    metric_settings_models: CalibrationMetricSettings\n    | Sequence[CalibrationMetricSettings],\n    parameter_names: str | Iterable[str],\n    formulation_settings_model: BaseFormulationSettings | None = None,\n    **formulation_settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        disciplines: The disciplines\n            whose parameters must be calibrated from the reference data.\n        input_names: The names of the inputs to be considered for the calibration.\n        metric_settings_models: A collection of calibration settings,\n            including the name of the observed output,\n            the name of the calibration metric\n            and the corresponding weight comprised between 0 and 1\n            (the weights must sum to 1).\n            When the output is a 1D function discretized over a mesh,\n            the name of the mesh can be provided.\n            E.g. `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")`\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)`\n            or\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")`\n            Lastly, `CalibrationMetric` can be imported\n            from [gemseo_calibration.calibrator][gemseo_calibration.calibrator].\n        parameter_names: The names of the parameters to be calibrated.\n        formulation_settings_model: The MDO formulation settings\n            as a Pydantic model.\n            If ``None``, use ``**settings``.\n        **formulation_settings: The MDO formulation settings,\n            including the formulation name (use the keyword ``\"formulation_name\"``).\n            These arguments are ignored when ``settings_model`` is not ``None``.\n            If none and ``settings_model`` is ``None``,\n            the calibrator uses the default MDF formulation.\n    \"\"\"  # noqa: D205,D212,D415,E501\n    self.__metric_factory = CalibrationMetricFactory()\n    input_names = self.__to_iterable(input_names, str)\n    metric_settings_models = self.__to_iterable(\n        metric_settings_models, CalibrationMetricSettings\n    )\n    parameter_names = self.__to_iterable(parameter_names, str)\n    disciplines = self.__to_iterable(disciplines, Discipline)\n    input_space = DesignSpace()\n    for input_name in input_names:\n        input_space.add_variable(input_name)\n\n    if (\n        formulation_settings_model is None\n        and \"formulation_name\" not in formulation_settings\n    ):\n        formulation_settings[\"formulation_name\"] = \"MDF\"\n\n    doe_scenario = DOEScenario(\n        disciplines,\n        metric_settings_models[0].output_name,\n        input_space,\n        formulation_settings_model=formulation_settings_model,\n        **formulation_settings,\n    )\n    if mesh_name := metric_settings_models[0].mesh_name:\n        doe_scenario.add_observable(mesh_name)\n\n    for metric_settings_model in metric_settings_models[1:]:\n        doe_scenario.add_observable(metric_settings_model.output_name)\n        if mesh_name := metric_settings_model.mesh_name:\n            doe_scenario.add_observable(mesh_name)\n\n    doe_scenario.set_algorithm(algo_name=CustomDOE.__name__)\n\n    self.__names_to_metrics = {}\n    self.__metrics = []\n    self.objective_name, output_names = self._add_metric(metric_settings_models)\n    super().__init__(doe_scenario, parameter_names, output_names, name=\"Calibrator\")\n    self.__update_output_grammar()\n    self.__reference_data = {}\n</code></pre>"},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator.maximize_objective_metric","title":"maximize_objective_metric  <code>property</code>","text":"<pre><code>maximize_objective_metric: bool\n</code></pre> <p>Whether to maximize the calibration metric related to the objectives.</p>"},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator.reference_data","title":"reference_data  <code>property</code>","text":"<pre><code>reference_data: DataType\n</code></pre> <p>The reference data used for the calibration.</p>"},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator.add_metric","title":"add_metric","text":"<pre><code>add_metric(\n    metric_settings_models: (\n        CalibrationMetricSettings\n        | Iterable[CalibrationMetricSettings]\n    ),\n) -&gt; tuple[str, list[str]]\n</code></pre> <p>Create a new calibration metric and add it to the outputs of the adapter.</p> <p>Parameters:</p> <ul> <li> <code>metric_settings_models</code>               (<code>CalibrationMetricSettings | Iterable[CalibrationMetricSettings]</code>)           \u2013            <p>A collection of calibration settings, including the name of the observed output, the name of the calibration metric and the corresponding weight comprised between 0 and 1 (the weights must sum to 1). When the output is a 1D function discretized over a mesh, the name of the mesh can be provided. E.g. <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")</code> <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)</code> or <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")</code> from gemseo_calibration.metrics.settings.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[str, list[str]]</code>           \u2013            <p>The name of the calibration metric applied to the outputs.</p> </li> </ul> Source code in <code>src/gemseo_calibration/calibrator.py</code> <pre><code>def add_metric(\n    self,\n    metric_settings_models: CalibrationMetricSettings\n    | Iterable[CalibrationMetricSettings],\n) -&gt; tuple[str, list[str]]:\n    \"\"\"Create a new calibration metric and add it to the outputs of the adapter.\n\n    Args:\n        metric_settings_models: A collection of calibration settings,\n            including the name of the observed output,\n            the name of the calibration metric\n            and the corresponding weight comprised between 0 and 1\n            (the weights must sum to 1).\n            When the output is a 1D function discretized over a mesh,\n            the name of the mesh can be provided.\n            E.g. `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")`\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)`\n            or\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")`\n            from\n            [gemseo_calibration.metrics.settings][gemseo_calibration.metrics.settings].\n\n    Returns:\n        The name of the calibration metric applied to the outputs.\n    \"\"\"  # noqa: E501\n    metric_settings_models = self.__to_metric_settings(metric_settings_models)\n    for metric_settings_model in metric_settings_models:\n        self.scenario.add_observable(metric_settings_model.output_name)\n        if mesh_name := metric_settings_model.mesh_name:\n            self.scenario.add_observable(mesh_name)\n\n    return_values = self._add_metric(metric_settings_models)\n    self.__update_output_grammar()\n    return return_values\n</code></pre>"},{"location":"reference/gemseo_calibration/calibrator/#gemseo_calibration.calibrator.Calibrator.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_data: DataType) -&gt; None\n</code></pre> <p>Pass the reference data to the scenario and to the metrics.</p> <p>Parameters:</p> <ul> <li> <code>reference_data</code>               (<code>DataType</code>)           \u2013            <p>The reference data with which to compare the discipline.</p> </li> </ul> Source code in <code>src/gemseo_calibration/calibrator.py</code> <pre><code>def set_reference_data(self, reference_data: DataType) -&gt; None:\n    \"\"\"Pass the reference data to the scenario and to the metrics.\n\n    Args:\n        reference_data: The reference data with which to compare the discipline.\n    \"\"\"\n    self.__reference_data = reference_data\n    design_space = self.scenario.design_space\n    for name in tuple(design_space):\n        design_space.remove_variable(name)\n        design_space.add_variable(name, size=reference_data[name].shape[1])\n\n    self.scenario.set_algorithm(\n        algo_name=\"CustomDOE\",\n        samples=hstack([\n            reference_data[name]\n            for name in self.scenario.get_optim_variable_names()\n        ]),\n    )\n    for metric in self.__metrics:\n        metric.set_reference_data(self.__reference_data)\n</code></pre>"},{"location":"reference/gemseo_calibration/post_processor/","title":"Post processor","text":""},{"location":"reference/gemseo_calibration/post_processor/#gemseo_calibration.post_processor","title":"post_processor","text":"<p>Base class for all calibration post-processing methods.</p>"},{"location":"reference/gemseo_calibration/post_processor/#gemseo_calibration.post_processor-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/post_processor/#gemseo_calibration.post_processor-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/post_processor/#gemseo_calibration.post_processor.CalibrationPostProcessor","title":"CalibrationPostProcessor","text":"<pre><code>CalibrationPostProcessor(\n    opt_problem: OptimizationProblem,\n    reference_data: DataType,\n    prior_model_data: DataType,\n    posterior_model_data: DataType,\n)\n</code></pre> <p>               Bases: <code>BasePost</code>, <code>Generic[T]</code></p> <p>Abstract class for optimization post-processing methods.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>opt_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The optimization problem to run.</p> </li> <li> <code>reference_data</code>               (<code>DataType</code>)           \u2013            <p>The reference data.</p> </li> <li> <code>prior_model_data</code>               (<code>DataType</code>)           \u2013            <p>The model data before the calibration.</p> </li> <li> <code>posterior_model_data</code>               (<code>DataType</code>)           \u2013            <p>The model data after the calibration.</p> </li> </ul> Source code in <code>src/gemseo_calibration/post_processor.py</code> <pre><code>def __init__(\n    self,\n    opt_problem: OptimizationProblem,\n    reference_data: DataType,\n    prior_model_data: DataType,\n    posterior_model_data: DataType,\n) -&gt; None:\n    \"\"\"\n    Args:\n        opt_problem: The optimization problem to run.\n        reference_data: The reference data.\n        prior_model_data: The model data before the calibration.\n        posterior_model_data: The model data after the calibration.\n    \"\"\"  # noqa: D205, D212, D415\n    super().__init__(opt_problem)\n    self._reference_data = reference_data\n    self._prior_model_data = prior_model_data\n    self._posterior_model_data = posterior_model_data\n</code></pre>"},{"location":"reference/gemseo_calibration/scenario/","title":"Scenario","text":""},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario","title":"scenario","text":"<p>A module to calibrate a multidisciplinary system from data.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario","title":"CalibrationScenario","text":"<pre><code>CalibrationScenario(\n    disciplines: Discipline | list[Discipline],\n    input_names: str | Iterable[str],\n    metric_settings_models: (\n        CalibrationMetricSettings\n        | Sequence[CalibrationMetricSettings]\n    ),\n    calibration_space: DesignSpace,\n    name: str = \"\",\n    formulation_settings_model: (\n        BaseFormulationSettings | None\n    ) = None,\n    **formulation_settings: Any\n)\n</code></pre> <p>               Bases: <code>MDOScenario</code></p> <p>A scenario to calibrate a multidisciplinary system from reference data.</p> <p>Set from parameters, this multidisciplinary system computes output data from input data.</p> <p>The reference input-output data are used to calibrate the parameters so that the model output data are close to the reference output data for some outputs of interest. This distance is evaluated with a BaseCalibrationMetric to compare the discipline outputs with the reference data.</p> Warning <p>Just like inputs, the parameters should be defined in the input grammars of the disciplines.</p> <p>The parameters are calibrated with the method <code>execute()</code> from an optimizer and a reference IODataset.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>disciplines</code>               (<code>Discipline | list[Discipline]</code>)           \u2013            <p>The disciplines whose parameters must be calibrated from the reference data.</p> </li> <li> <code>input_names</code>               (<code>str | Iterable[str]</code>)           \u2013            <p>The names of the inputs to be considered for the calibration.</p> </li> <li> <code>metric_settings_models</code>               (<code>CalibrationMetricSettings | Sequence[CalibrationMetricSettings]</code>)           \u2013            <p>A collection of calibration settings, including the name of the observed output, the name of the calibration metric and the corresponding weight comprised between 0 and 1 (the weights must sum to 1). When the output is a 1D function discretized over a mesh, the name of the mesh can be provided. E.g. <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")</code> <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)</code> or <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")</code> Lastly, <code>CalibrationMetricSettings</code> can be imported from gemseo_calibration.metrics.settings.</p> </li> <li> <code>calibration_space</code>               (<code>DesignSpace</code>)           \u2013            <p>The space of the parameters to be calibrated, whose current values are consider as a prior for calibration.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>A name for this calibration scenario. If empty, use the name of the class.</p> </li> <li> <code>formulation_settings_model</code>               (<code>BaseFormulationSettings | None</code>, default:                   <code>None</code> )           \u2013            <p>The formulation settings as a Pydantic model. If <code>None</code>, use <code>**settings</code>.</p> </li> <li> <code>**formulation_settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The formulation settings, including the formulation name (use the keyword <code>\"formulation_name\"</code>). These arguments are ignored when <code>settings_model</code> is not <code>None</code>. If none and <code>settings_model</code> is <code>None</code>, the calibrator uses the default MDF formulation.</p> </li> </ul> Source code in <code>src/gemseo_calibration/scenario.py</code> <pre><code>def __init__(\n    self,\n    disciplines: Discipline | list[Discipline],\n    input_names: str | Iterable[str],\n    metric_settings_models: CalibrationMetricSettings\n    | Sequence[CalibrationMetricSettings],\n    calibration_space: DesignSpace,\n    name: str = \"\",\n    formulation_settings_model: BaseFormulationSettings | None = None,\n    **formulation_settings: Any,\n) -&gt; None:\n    \"\"\"\n    Args:\n        disciplines: The disciplines\n            whose parameters must be calibrated from the reference data.\n        input_names: The names of the inputs to be considered for the calibration.\n        metric_settings_models: A collection of calibration settings,\n            including the name of the observed output,\n            the name of the calibration metric\n            and the corresponding weight comprised between 0 and 1\n            (the weights must sum to 1).\n            When the output is a 1D function discretized over a mesh,\n            the name of the mesh can be provided.\n            E.g. `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")`\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)`\n            or\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")`\n            Lastly, `CalibrationMetricSettings` can be imported\n            from\n            [gemseo_calibration.metrics.settings][gemseo_calibration.metrics.settings].\n        calibration_space: The space of the parameters to be calibrated,\n            whose current values are consider as a prior for calibration.\n        name: A name for this calibration scenario.\n            If empty, use the name of the class.\n        formulation_settings_model: The formulation settings as a Pydantic model.\n            If ``None``, use ``**settings``.\n        **formulation_settings: The formulation settings,\n            including the formulation name (use the keyword ``\"formulation_name\"``).\n            These arguments are ignored when ``settings_model`` is not ``None``.\n            If none and ``settings_model`` is ``None``,\n            the calibrator uses the default MDF formulation.\n    \"\"\"  # noqa: D205,D212,D415,E501\n    self.__prior_parameters = calibration_space.get_current_value(as_dict=True)\n    self.__posterior_parameters = {}\n    self.prior_model_data = {}\n    self.posterior_model_data = {}\n    self.__reference_data = {}\n    calibrator = Calibrator(\n        disciplines,\n        input_names,\n        metric_settings_models,\n        calibration_space.variable_names,\n        formulation_settings_model=formulation_settings_model,\n        **formulation_settings,\n    )\n    super().__init__(\n        [calibrator],\n        calibrator.objective_name,\n        calibration_space,\n        name=name or self.__class__.__name__,\n        formulation_name=\"DisciplinaryOpt\",\n        maximize_objective=calibrator.maximize_objective_metric,\n    )\n    self.__calibration_post_factory = CalibrationPostFactory()\n</code></pre>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.calibrator","title":"calibrator  <code>property</code>","text":"<pre><code>calibrator: Calibrator\n</code></pre> <p>The discipline computing calibration metrics from the parameter values.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.posterior_model_data","title":"posterior_model_data  <code>instance-attribute</code>","text":"<pre><code>posterior_model_data: dict[str, RealArray] = {}\n</code></pre> <p>The model data after the calibration.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.posterior_parameters","title":"posterior_parameters  <code>property</code>","text":"<pre><code>posterior_parameters: DataType\n</code></pre> <p>The values of the parameters after the calibration stage.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.prior_model_data","title":"prior_model_data  <code>instance-attribute</code>","text":"<pre><code>prior_model_data: dict[str, RealArray] = {}\n</code></pre> <p>The model data before the calibration.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.prior_parameters","title":"prior_parameters  <code>property</code>","text":"<pre><code>prior_parameters: DataType\n</code></pre> <p>The values of the parameters before the calibration stage.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.reference_data","title":"reference_data  <code>instance-attribute</code>","text":"<pre><code>reference_data: StrKeyMapping\n</code></pre> <p>The reference data, if defined.</p>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.add_constraint","title":"add_constraint","text":"<pre><code>add_constraint(\n    metric_settings_models: (\n        CalibrationMetricSettings\n        | Iterable[CalibrationMetricSettings]\n    ),\n    constraint_type: ConstraintType = EQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n) -&gt; None\n</code></pre> <p>Define a constraint from a calibration metric related to discipline outputs.</p> <p>Parameters:</p> <ul> <li> <code>metric_settings_models</code>               (<code>CalibrationMetricSettings | Iterable[CalibrationMetricSettings]</code>)           \u2013            <p>A collection of calibration settings, including the name of the observed output, the name of the calibration metric and the corresponding weight comprised between 0 and 1 (the weights must sum to 1). When the output is a 1D function discretized over a mesh, the name of the mesh can be provided. E.g. <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")</code> <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)</code> or <code>CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")</code> Lastly, <code>CalibrationMetricSettings</code> can be imported from gemseo_calibration.metrics.settings.</p> </li> <li> <code>constraint_type</code>               (<code>ConstraintType</code>, default:                   <code>EQ</code> )           \u2013            <p>The type of constraint, <code>\"eq\"</code> for equality constraint and <code>\"ineq\"</code> for inequality constraint.</p> </li> <li> <code>constraint_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the constraint to be stored. If empty, the name of the constraint is generated from the output name.</p> </li> <li> <code>value</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>The value for which the constraint is active.</p> </li> <li> <code>positive</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to consider the inequality constraint as positive.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the constraint type is neither 'eq' nor 'ineq'.</p> </li> </ul> Source code in <code>src/gemseo_calibration/scenario.py</code> <pre><code>def add_constraint(\n    self,\n    metric_settings_models: CalibrationMetricSettings\n    | Iterable[CalibrationMetricSettings],\n    constraint_type: MDOFunction.ConstraintType = MDOFunction.ConstraintType.EQ,\n    constraint_name: str = \"\",\n    value: float = 0.0,\n    positive: bool = False,\n) -&gt; None:\n    \"\"\"Define a constraint from a calibration metric related to discipline outputs.\n\n    Args:\n        metric_settings_models: A collection of calibration settings,\n            including the name of the observed output,\n            the name of the calibration metric\n            and the corresponding weight comprised between 0 and 1\n            (the weights must sum to 1).\n            When the output is a 1D function discretized over a mesh,\n            the name of the mesh can be provided.\n            E.g. `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\")`\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", weight=0.3)`\n            or\n            `CalibrationMetricSettings(output_name=\"z\", metric_name=\"MSE\", mesh_name=\"z_mesh\")`\n            Lastly, `CalibrationMetricSettings` can be imported\n            from\n            [gemseo_calibration.metrics.settings][gemseo_calibration.metrics.settings].\n        constraint_type: The type of constraint,\n            `\"eq\"` for equality constraint and\n            `\"ineq\"` for inequality constraint.\n        constraint_name: The name of the constraint to be stored.\n            If empty,\n            the name of the constraint is generated from the output name.\n        value: The value for which the constraint is active.\n        positive: Whether to consider the inequality constraint as positive.\n    \"\"\"  # noqa: E501\n    super().add_constraint(\n        self.calibrator.add_metric(metric_settings_models)[0],\n        constraint_type,\n        constraint_name,\n        value,\n        positive,\n    )\n</code></pre>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.post_process","title":"post_process","text":"<pre><code>post_process(\n    settings_model: BasePostSettings | None = None,\n    **settings: Any\n) -&gt; BasePost\n</code></pre> <p>Post-process the optimization history.</p> <p>Parameters:</p> <ul> <li> <code>settings_model</code>               (<code>BasePostSettings | None</code>, default:                   <code>None</code> )           \u2013            <p>The post-processor settings as a Pydantic model. If <code>None</code>, use <code>**settings</code>.</p> </li> <li> <code>**settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The post-processor settings, including the algorithm name (use the keyword <code>\"post_name\"</code>). These arguments are ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BasePost</code>           \u2013            <p>The post-processor.</p> </li> </ul> Source code in <code>src/gemseo_calibration/scenario.py</code> <pre><code>def post_process(  # noqa: D102\n    self, settings_model: BasePostSettings | None = None, **settings: Any\n) -&gt; BasePost:\n    post_name = get_class_name(settings_model, settings, class_name_arg=\"post_name\")\n    if post_name in self.__calibration_post_factory.class_names:\n        return self.__calibration_post_factory.execute(\n            self.formulation.optimization_problem,\n            self.calibrator.reference_data,\n            self.prior_model_data,\n            self.posterior_model_data,\n            post_name,\n            **settings,\n        )\n\n    return super().post_process(post_name=post_name, **settings)\n</code></pre>"},{"location":"reference/gemseo_calibration/scenario/#gemseo_calibration.scenario.CalibrationScenario.set_algorithm","title":"set_algorithm","text":"<pre><code>set_algorithm(\n    reference_data: StrKeyMapping,\n    algo_settings_model: BaseDriverSettings | None = None,\n    **algo_settings: Any\n) -&gt; None\n</code></pre> <p>Define the algorithm to execute the scenario.</p> <p>Parameters:</p> <ul> <li> <code>reference_data</code>               (<code>StrKeyMapping</code>)           \u2013            <p>The description is missing.</p> </li> <li> <code>algo_settings_model</code>               (<code>BaseDriverSettings | None</code>, default:                   <code>None</code> )           \u2013            <p>The algorithm settings as a Pydantic model. If <code>None</code>, use <code>**settings</code>.</p> </li> <li> <code>**algo_settings</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The algorithm settings, including the algorithm name (use the keyword <code>\"algo_name\"</code>). These arguments are ignored when <code>settings_model</code> is not <code>None</code>.</p> </li> </ul> Source code in <code>src/gemseo_calibration/scenario.py</code> <pre><code>def set_algorithm(  # noqa:D102\n    self,\n    reference_data: StrKeyMapping,\n    algo_settings_model: BaseDriverSettings | None = None,\n    **algo_settings: Any,\n) -&gt; None:\n    self.__reference_data = reference_data\n    super().set_algorithm(algo_settings_model=algo_settings_model, **algo_settings)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/","title":"Metrics","text":""},{"location":"reference/gemseo_calibration/metrics/#gemseo_calibration.metrics","title":"metrics","text":"<p>Metrics to compare data sets.</p>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/","title":"Base calibration metric","text":""},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric","title":"base_calibration_metric","text":"<p>Base class for metrics to compare data sets.</p>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.DataType","title":"DataType  <code>module-attribute</code>","text":"<pre><code>DataType = dict[str, RealArray]\n</code></pre> <p>The type of data.</p> <p>The data are set as <code>{variable_name: variable_values}</code> where <code>variable_values</code> is a 2D NumPy array whose rows are the samples and columns are the components of the variable.</p>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric","title":"BaseCalibrationMetric","text":"<pre><code>BaseCalibrationMetric(\n    output_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>MDOFunction</code></p> <p>The base class for metrics to compare data sets.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output to be taken into account by the metric.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    name: str = \"\",\n    f_type: MDOFunction.FunctionType = MDOFunction.FunctionType.NONE,\n) -&gt; None:\n    \"\"\"\n    Args:\n        output_name: The name of the output to be taken into account by the metric.\n    \"\"\"  # noqa: D205,D212,D415\n    self.output_name = output_name\n    super().__init__(\n        self._evaluate_metric, name or self._compute_name(), f_type=f_type\n    )\n    self._reference_data = []\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/base_calibration_metric/#gemseo_calibration.metrics.base_calibration_metric.BaseCalibrationMetric.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:\n    \"\"\"Define the reference input-output data set.\n\n    Args:\n        reference_dataset: The reference input-output data set.\n    \"\"\"\n    self._reference_data = reference_dataset[self.output_name]\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/","title":"Base integrated metric","text":""},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric","title":"base_integrated_metric","text":"<p>Base class for integrated metrics.</p>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric","title":"BaseIntegratedMetric","text":"<pre><code>BaseIntegratedMetric(\n    output_name: str,\n    mesh_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>BaseCalibrationMetric</code></p> <p>The base class for integrated metrics.</p> <p>Parameters:</p> <ul> <li> <code>mesh_name</code>               (<code>str</code>)           \u2013            <p>The name of the 1D mesh.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_integrated_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    mesh_name: str,\n    name: str = \"\",\n    f_type: BaseCalibrationMetric.FunctionType = BaseCalibrationMetric.FunctionType.NONE,  # noqa: E501\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_name: The name of the 1D mesh.\n    \"\"\"  # noqa: D205 D212 D415\n    self.mesh_name = mesh_name\n    self.__reference_mesh = None\n    super().__init__(output_name, name=name, f_type=f_type)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric.mesh_name","title":"mesh_name  <code>instance-attribute</code>","text":"<pre><code>mesh_name: str = mesh_name\n</code></pre> <p>The name of the 1D mesh.</p>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/base_integrated_metric/#gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_integrated_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:  # noqa: D102\n    self.__reference_mesh = reference_dataset[self.mesh_name]\n    super().set_reference_data(reference_dataset)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/","title":"Base mean metric","text":""},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric","title":"base_mean_metric","text":"<p>Base class for mean calibration metrics.</p>"},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric","title":"BaseMeanMetric","text":"<pre><code>BaseMeanMetric(\n    output_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>BaseCalibrationMetric</code></p> <p>The base class for mean metrics between the model and reference output data.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output to be taken into account by the metric.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    name: str = \"\",\n    f_type: MDOFunction.FunctionType = MDOFunction.FunctionType.NONE,\n) -&gt; None:\n    \"\"\"\n    Args:\n        output_name: The name of the output to be taken into account by the metric.\n    \"\"\"  # noqa: D205,D212,D415\n    self.output_name = output_name\n    super().__init__(\n        self._evaluate_metric, name or self._compute_name(), f_type=f_type\n    )\n    self._reference_data = []\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/base_mean_metric/#gemseo_calibration.metrics.base_mean_metric.BaseMeanMetric.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:\n    \"\"\"Define the reference input-output data set.\n\n    Args:\n        reference_dataset: The reference input-output data set.\n    \"\"\"\n    self._reference_data = reference_dataset[self.output_name]\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/factory/","title":"Factory","text":""},{"location":"reference/gemseo_calibration/metrics/factory/#gemseo_calibration.metrics.factory","title":"factory","text":"<p>A factory of calibration metrics.</p>"},{"location":"reference/gemseo_calibration/metrics/factory/#gemseo_calibration.metrics.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/factory/#gemseo_calibration.metrics.factory.CalibrationMetricFactory","title":"CalibrationMetricFactory","text":"<p>               Bases: <code>BaseFactory</code></p> <p>A factory of calibration metrics.</p>"},{"location":"reference/gemseo_calibration/metrics/factory/#gemseo_calibration.metrics.factory.CalibrationMetricFactory-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/factory/#gemseo_calibration.metrics.factory.CalibrationMetricFactory.is_integrated_metric","title":"is_integrated_metric","text":"<pre><code>is_integrated_metric(name: str) -&gt; bool\n</code></pre> <p>Return whether a calibration metric is an integrated metric.</p> <p>See BaseIntegratedMetric.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>The name of the calibration metric.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>Whether the calibration metric is an integrated metric.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/factory.py</code> <pre><code>def is_integrated_metric(self, name: str) -&gt; bool:\n    \"\"\"Return whether a calibration metric is an integrated metric.\n\n    See\n    [BaseIntegratedMetric][gemseo_calibration.metrics.base_integrated_metric.BaseIntegratedMetric].\n\n    Args:\n        name: The name of the calibration metric.\n\n    Returns:\n        Whether the calibration metric is an integrated metric.\n    \"\"\"\n    return issubclass(self.get_class(name), BaseIntegratedMetric)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/iae/","title":"Iae","text":""},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae","title":"iae","text":"<p>Integrated absolute error between the model and reference output data.</p>"},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE","title":"IAE","text":"<pre><code>IAE(\n    output_name: str,\n    mesh_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>BaseIntegratedMetric</code></p> <p>The integrated absolute error between the model and reference output data.</p> <p>Parameters:</p> <ul> <li> <code>mesh_name</code>               (<code>str</code>)           \u2013            <p>The name of the 1D mesh.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_integrated_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    mesh_name: str,\n    name: str = \"\",\n    f_type: BaseCalibrationMetric.FunctionType = BaseCalibrationMetric.FunctionType.NONE,  # noqa: E501\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_name: The name of the 1D mesh.\n    \"\"\"  # noqa: D205 D212 D415\n    self.mesh_name = mesh_name\n    self.__reference_mesh = None\n    super().__init__(output_name, name=name, f_type=f_type)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE.mesh_name","title":"mesh_name  <code>instance-attribute</code>","text":"<pre><code>mesh_name: str = mesh_name\n</code></pre> <p>The name of the 1D mesh.</p>"},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/iae/#gemseo_calibration.metrics.iae.IAE.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_integrated_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:  # noqa: D102\n    self.__reference_mesh = reference_dataset[self.mesh_name]\n    super().set_reference_data(reference_dataset)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/ise/","title":"Ise","text":""},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise","title":"ise","text":"<p>Integrated square error between the model and reference output data.</p>"},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE","title":"ISE","text":"<pre><code>ISE(\n    output_name: str,\n    mesh_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>BaseIntegratedMetric</code></p> <p>The integrated square error between the model and reference output data.</p> <p>Parameters:</p> <ul> <li> <code>mesh_name</code>               (<code>str</code>)           \u2013            <p>The name of the 1D mesh.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_integrated_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    mesh_name: str,\n    name: str = \"\",\n    f_type: BaseCalibrationMetric.FunctionType = BaseCalibrationMetric.FunctionType.NONE,  # noqa: E501\n) -&gt; None:\n    \"\"\"\n    Args:\n        mesh_name: The name of the 1D mesh.\n    \"\"\"  # noqa: D205 D212 D415\n    self.mesh_name = mesh_name\n    self.__reference_mesh = None\n    super().__init__(output_name, name=name, f_type=f_type)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE.mesh_name","title":"mesh_name  <code>instance-attribute</code>","text":"<pre><code>mesh_name: str = mesh_name\n</code></pre> <p>The name of the 1D mesh.</p>"},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/ise/#gemseo_calibration.metrics.ise.ISE.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_integrated_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:  # noqa: D102\n    self.__reference_mesh = reference_dataset[self.mesh_name]\n    super().set_reference_data(reference_dataset)\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/mae/","title":"Mae","text":""},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae","title":"mae","text":"<p>Mean absolute error between the model and reference output data.</p>"},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE","title":"MAE","text":"<pre><code>MAE(\n    output_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>BaseMeanMetric</code></p> <p>The mean absolute error between the model and reference output data.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output to be taken into account by the metric.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    name: str = \"\",\n    f_type: MDOFunction.FunctionType = MDOFunction.FunctionType.NONE,\n) -&gt; None:\n    \"\"\"\n    Args:\n        output_name: The name of the output to be taken into account by the metric.\n    \"\"\"  # noqa: D205,D212,D415\n    self.output_name = output_name\n    super().__init__(\n        self._evaluate_metric, name or self._compute_name(), f_type=f_type\n    )\n    self._reference_data = []\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/mae/#gemseo_calibration.metrics.mae.MAE.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:\n    \"\"\"Define the reference input-output data set.\n\n    Args:\n        reference_dataset: The reference input-output data set.\n    \"\"\"\n    self._reference_data = reference_dataset[self.output_name]\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/mse/","title":"Mse","text":""},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse","title":"mse","text":"<p>Compute the mean square error between the model and reference output data.</p>"},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE","title":"MSE","text":"<pre><code>MSE(\n    output_name: str,\n    name: str = \"\",\n    f_type: FunctionType = NONE,\n)\n</code></pre> <p>               Bases: <code>BaseMeanMetric</code></p> <p>The mean square error between the model and reference output data.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output to be taken into account by the metric.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def __init__(\n    self,\n    output_name: str,\n    name: str = \"\",\n    f_type: MDOFunction.FunctionType = MDOFunction.FunctionType.NONE,\n) -&gt; None:\n    \"\"\"\n    Args:\n        output_name: The name of the output to be taken into account by the metric.\n    \"\"\"  # noqa: D205,D212,D415\n    self.output_name = output_name\n    super().__init__(\n        self._evaluate_metric, name or self._compute_name(), f_type=f_type\n    )\n    self._reference_data = []\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE-attributes","title":"Attributes","text":""},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE.full_output_name","title":"full_output_name  <code>property</code>","text":"<pre><code>full_output_name: str\n</code></pre> <p>The full name of the output.</p>"},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE.maximize","title":"maximize  <code>class-attribute</code>","text":"<pre><code>maximize: bool = False\n</code></pre> <p>Whether to maximize the calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE.output_name","title":"output_name  <code>instance-attribute</code>","text":"<pre><code>output_name: str = output_name\n</code></pre> <p>The name of the output used by the metric for calibration.</p>"},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/metrics/mse/#gemseo_calibration.metrics.mse.MSE.set_reference_data","title":"set_reference_data","text":"<pre><code>set_reference_data(reference_dataset: DataType) -&gt; None\n</code></pre> <p>Define the reference input-output data set.</p> <p>Parameters:</p> <ul> <li> <code>reference_dataset</code>               (<code>DataType</code>)           \u2013            <p>The reference input-output data set.</p> </li> </ul> Source code in <code>src/gemseo_calibration/metrics/base_calibration_metric.py</code> <pre><code>def set_reference_data(self, reference_dataset: DataType) -&gt; None:\n    \"\"\"Define the reference input-output data set.\n\n    Args:\n        reference_dataset: The reference input-output data set.\n    \"\"\"\n    self._reference_data = reference_dataset[self.output_name]\n</code></pre>"},{"location":"reference/gemseo_calibration/metrics/settings/","title":"Settings","text":""},{"location":"reference/gemseo_calibration/metrics/settings/#gemseo_calibration.metrics.settings","title":"settings","text":"<p>The settings of a calibration metric.</p>"},{"location":"reference/gemseo_calibration/metrics/settings/#gemseo_calibration.metrics.settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/metrics/settings/#gemseo_calibration.metrics.settings.CalibrationMetricSettings","title":"CalibrationMetricSettings","text":"<p>               Bases: <code>BaseModel</code></p> <p>The settings of a calibration metric.</p> <p>Parameters:</p> <ul> <li> <code>output_name</code>               (<code>str</code>)           \u2013            <p>The name of the output.</p> </li> <li> <code>metric_name</code>               (<code>str</code>, default:                   <code>'MSE'</code> )           \u2013            <p>The name of the metric to compare the observed and simulated outputs.</p> </li> <li> <code>mesh_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the mesh associated with the output if any.</p> <p>To be used when the output is a 1D function discretized over a mesh.</p> </li> <li> <code>weight</code>               (<code>Annotated[float, Gt(gt=0)] | None</code>, default:                   <code>None</code> )           \u2013            <p>The weight of this calibration metric when this calibration metric is an element of a collection of calibration metrics.</p> <p>The weight must be between 0 and 1. The sum of the weights of the elements in the collection must be 1. In a collection, all the calibration metrics with <code>weight</code> set to <code>None</code> will have the same weight.</p> </li> </ul>"},{"location":"reference/gemseo_calibration/post/","title":"Post","text":""},{"location":"reference/gemseo_calibration/post/#gemseo_calibration.post","title":"post","text":"<p>The post-processing methods for the calibration scenarios.</p>"},{"location":"reference/gemseo_calibration/post/factory/","title":"Factory","text":""},{"location":"reference/gemseo_calibration/post/factory/#gemseo_calibration.post.factory","title":"factory","text":"<p>A factory to post-process a <code>CalibrationScenario</code>.</p>"},{"location":"reference/gemseo_calibration/post/factory/#gemseo_calibration.post.factory-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/post/factory/#gemseo_calibration.post.factory.CalibrationPostFactory","title":"CalibrationPostFactory","text":"<p>               Bases: <code>PostFactory</code></p> <p>A factory for calibration post-processing.</p>"},{"location":"reference/gemseo_calibration/post/factory/#gemseo_calibration.post.factory.CalibrationPostFactory-functions","title":"Functions","text":""},{"location":"reference/gemseo_calibration/post/factory/#gemseo_calibration.post.factory.CalibrationPostFactory.create","title":"create","text":"<pre><code>create(\n    post_name: str,\n    opt_problem: OptimizationProblem,\n    reference_data: Dataset,\n    prior_model_data: Dataset,\n    posterior_model_data: Dataset,\n) -&gt; CalibrationPostProcessor\n</code></pre> <p>Create the post-processing.</p> <p>Parameters:</p> <ul> <li> <code>post_name</code>               (<code>str</code>)           \u2013            <p>The name of the post-processing method.</p> </li> <li> <code>opt_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The optimization problem containing the data to post-process.</p> </li> <li> <code>reference_data</code>               (<code>Dataset</code>)           \u2013            <p>The reference data used during the calibration stage.</p> </li> <li> <code>prior_model_data</code>               (<code>Dataset</code>)           \u2013            <p>The model data before the calibration stage.</p> </li> <li> <code>posterior_model_data</code>               (<code>Dataset</code>)           \u2013            <p>The model data after the calibration stage.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>CalibrationPostProcessor</code>           \u2013            <p>The post-processing of the optimization problem.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If the class cannot be instantiated.</p> </li> </ul> Source code in <code>src/gemseo_calibration/post/factory.py</code> <pre><code>def create(\n    self,\n    post_name: str,\n    opt_problem: OptimizationProblem,\n    reference_data: Dataset,\n    prior_model_data: Dataset,\n    posterior_model_data: Dataset,\n) -&gt; CalibrationPostProcessor:\n    \"\"\"Create the post-processing.\n\n    Args:\n        opt_problem: The optimization problem containing the data to post-process.\n        reference_data: The reference data used during the calibration stage.\n        prior_model_data: The model data before the calibration stage.\n        posterior_model_data: The model data after the calibration stage.\n        post_name: The name of the post-processing method.\n\n    Returns:\n        The post-processing of the optimization problem.\n    \"\"\"\n    return super().create(\n        post_name,\n        reference_data=reference_data,\n        prior_model_data=prior_model_data,\n        posterior_model_data=posterior_model_data,\n        opt_problem=opt_problem,\n    )\n</code></pre>"},{"location":"reference/gemseo_calibration/post/factory/#gemseo_calibration.post.factory.CalibrationPostFactory.execute","title":"execute","text":"<pre><code>execute(\n    opt_problem: str | OptimizationProblem,\n    reference_data: Dataset,\n    prior_model_data: Dataset,\n    posterior_model_data: Dataset,\n    post_name: str,\n    save: bool = True,\n    show: bool = False,\n    file_path: str | Path = \"\",\n    directory_path: str | Path = \"\",\n    file_name: str = \"\",\n    file_extension: str = \"\",\n    **options: Any\n) -&gt; CalibrationPostProcessor\n</code></pre> <p>Compute the post-processing.</p> <p>Parameters:</p> <ul> <li> <code>opt_problem</code>               (<code>str | OptimizationProblem</code>)           \u2013            <p>The optimization problem containing the data to post-process.</p> </li> <li> <code>reference_data</code>               (<code>Dataset</code>)           \u2013            <p>The reference data used during the calibration stage.</p> </li> <li> <code>prior_model_data</code>               (<code>Dataset</code>)           \u2013            <p>The model data before the calibration stage.</p> </li> <li> <code>posterior_model_data</code>               (<code>Dataset</code>)           \u2013            <p>The model data after the calibration stage.</p> </li> <li> <code>post_name</code>               (<code>str</code>)           \u2013            <p>The name of the post-processing method.</p> </li> <li> <code>save</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to save the figure.</p> </li> <li> <code>show</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display the figure.</p> </li> <li> <code>file_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The path of the file to save the figures. If the extension is missing, use <code>file_extension</code>. If empty, create a file path from <code>directory_path</code>, <code>file_name</code> and <code>file_extension</code>.</p> </li> <li> <code>directory_path</code>               (<code>str | Path</code>, default:                   <code>''</code> )           \u2013            <p>The path of the directory to save the figures. If empty, use the current working directory.</p> </li> <li> <code>file_name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The name of the file to save the figures. If empty, use a default one generated by the post-processing.</p> </li> <li> <code>file_extension</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>A file extension, e.g. 'png', 'pdf', 'svg', ... If empty, use a default file extension.</p> </li> <li> <code>**options</code>               (<code>Any</code>, default:                   <code>{}</code> )           \u2013            <p>The options of the post-processor.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>CalibrationPostProcessor</code>           \u2013            <p>The executed post-processing of the optimization problem.</p> </li> </ul> Source code in <code>src/gemseo_calibration/post/factory.py</code> <pre><code>def execute(\n    self,\n    opt_problem: str | OptimizationProblem,\n    reference_data: Dataset,\n    prior_model_data: Dataset,\n    posterior_model_data: Dataset,\n    post_name: str,\n    save: bool = True,\n    show: bool = False,\n    file_path: str | Path = \"\",\n    directory_path: str | Path = \"\",\n    file_name: str = \"\",\n    file_extension: str = \"\",\n    **options: Any,\n) -&gt; CalibrationPostProcessor:\n    \"\"\"Compute the post-processing.\n\n    Args:\n        opt_problem: The optimization problem containing the data to post-process.\n        reference_data: The reference data used during the calibration stage.\n        prior_model_data: The model data before the calibration stage.\n        posterior_model_data: The model data after the calibration stage.\n        post_name: The name of the post-processing method.\n        save: Whether to save the figure.\n        show: Whether to display the figure.\n        file_path: The path of the file to save the figures.\n            If the extension is missing, use `file_extension`.\n            If empty,\n            create a file path\n            from `directory_path`, `file_name` and `file_extension`.\n        directory_path: The path of the directory to save the figures.\n            If empty, use the current working directory.\n        file_name: The name of the file to save the figures.\n            If empty, use a default one generated by the post-processing.\n        file_extension: A file extension, e.g. 'png', 'pdf', 'svg', ...\n            If empty, use a default file extension.\n        **options: The options of the post-processor.\n\n    Returns:\n        The executed post-processing of the optimization problem.\n    \"\"\"\n    if isinstance(opt_problem, str):\n        opt_problem = OptimizationProblem.from_hdf(opt_problem)\n    post = self.create(\n        post_name,\n        opt_problem,\n        reference_data,\n        prior_model_data,\n        posterior_model_data,\n    )\n    post.execute(\n        save=save,\n        show=show,\n        file_path=file_path,\n        directory_path=directory_path,\n        file_name=file_name,\n        file_extension=file_extension,\n        **options,\n    )\n    return post\n</code></pre>"},{"location":"reference/gemseo_calibration/post/multiple_scatter/","title":"Multiple scatter","text":""},{"location":"reference/gemseo_calibration/post/multiple_scatter/#gemseo_calibration.post.multiple_scatter","title":"multiple_scatter","text":"<p>Overlay several scatter plots from a <code>Dataset</code>.</p> <p>A scatter plot represents a set of points \\(\\{x_i,y_i\\}_{1\\leq i \\leq n}\\) as markers on a classical plot, while a multiple-scatter plot represents a set of points \\(\\{x_i,y_{i,1},\\ldots,y_{i,d}\\}_{1\\leq i \\leq n}\\) as markers on a classical plot, with one color per series \\(\\{y_i\\}_{1\\leq i \\leq n}\\).</p>"},{"location":"reference/gemseo_calibration/post/multiple_scatter/#gemseo_calibration.post.multiple_scatter-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/post/multiple_scatter/#gemseo_calibration.post.multiple_scatter.MultipleScatter","title":"MultipleScatter","text":"<pre><code>MultipleScatter(\n    dataset: Dataset,\n    x: str,\n    y: str | Iterable[str],\n    x_comp: int = 0,\n    y_comp: Mapping[str, int] = MappingProxyType({}),\n)\n</code></pre> <p>               Bases: <code>DatasetPlot</code></p> <p>Overlay several scatter y_i versus x.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>               (<code>Dataset</code>)           \u2013            <p>The dataset containing the data to plot.</p> </li> <li> <code>x</code>               (<code>str</code>)           \u2013            <p>The name of the variable on the x-axis.</p> </li> <li> <code>y</code>               (<code>str | Iterable[str]</code>)           \u2013            <p>The names of the variables on the y-axis.</p> </li> <li> <code>x_comp</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The component of x.</p> </li> <li> <code>y_comp</code>               (<code>Mapping[str, int]</code>, default:                   <code>MappingProxyType({})</code> )           \u2013            <p>The components of y, where the names are the names of the variables and the values are the components. If empty or if a name is missing, use the first component.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the dataset is empty.</p> </li> </ul> Source code in <code>src/gemseo_calibration/post/multiple_scatter.py</code> <pre><code>def __init__(\n    self,\n    dataset: Dataset,\n    x: str,\n    y: str | Iterable[str],\n    x_comp: int = 0,\n    y_comp: Mapping[str, int] = MappingProxyType({}),\n) -&gt; None:\n    \"\"\"\n    Args:\n        x: The name of the variable on the x-axis.\n        y: The names of the variables on the y-axis.\n        x_comp: The component of x.\n        y_comp: The components of y,\n            where the names are the names of the variables\n            and the values are the components.\n            If empty or if a name is missing,\n            use the first component.\n    \"\"\"  # noqa: D205 D212 D415\n    super().__init__(dataset=dataset, x=x, y=y, x_comp=x_comp, y_comp=y_comp)\n</code></pre>"},{"location":"reference/gemseo_calibration/post/data_versus_model/","title":"Data versus model","text":""},{"location":"reference/gemseo_calibration/post/data_versus_model/#gemseo_calibration.post.data_versus_model","title":"data_versus_model","text":"<p>Method to plot model data versus reference ones.</p>"},{"location":"reference/gemseo_calibration/post/data_versus_model/post/","title":"Post","text":""},{"location":"reference/gemseo_calibration/post/data_versus_model/post/#gemseo_calibration.post.data_versus_model.post","title":"post","text":"<p>Plot the model data versus the reference data.</p>"},{"location":"reference/gemseo_calibration/post/data_versus_model/post/#gemseo_calibration.post.data_versus_model.post-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/post/data_versus_model/post/#gemseo_calibration.post.data_versus_model.post.DataVersusModel","title":"DataVersusModel","text":"<pre><code>DataVersusModel(\n    opt_problem: OptimizationProblem,\n    reference_data: DataType,\n    prior_model_data: DataType,\n    posterior_model_data: DataType,\n)\n</code></pre> <p>               Bases: <code>CalibrationPostProcessor[DataVersusModelSettings]</code></p> <p>Scatter plot of the model data versus the reference ones.</p> <p>Initialize self.  See help(type(self)) for accurate signature.</p> <p>Parameters:</p> <ul> <li> <code>opt_problem</code>               (<code>OptimizationProblem</code>)           \u2013            <p>The optimization problem to run.</p> </li> <li> <code>reference_data</code>               (<code>DataType</code>)           \u2013            <p>The reference data.</p> </li> <li> <code>prior_model_data</code>               (<code>DataType</code>)           \u2013            <p>The model data before the calibration.</p> </li> <li> <code>posterior_model_data</code>               (<code>DataType</code>)           \u2013            <p>The model data after the calibration.</p> </li> </ul> Source code in <code>src/gemseo_calibration/post_processor.py</code> <pre><code>def __init__(\n    self,\n    opt_problem: OptimizationProblem,\n    reference_data: DataType,\n    prior_model_data: DataType,\n    posterior_model_data: DataType,\n) -&gt; None:\n    \"\"\"\n    Args:\n        opt_problem: The optimization problem to run.\n        reference_data: The reference data.\n        prior_model_data: The model data before the calibration.\n        posterior_model_data: The model data after the calibration.\n    \"\"\"  # noqa: D205, D212, D415\n    super().__init__(opt_problem)\n    self._reference_data = reference_data\n    self._prior_model_data = prior_model_data\n    self._posterior_model_data = posterior_model_data\n</code></pre>"},{"location":"reference/gemseo_calibration/post/data_versus_model/settings/","title":"Settings","text":""},{"location":"reference/gemseo_calibration/post/data_versus_model/settings/#gemseo_calibration.post.data_versus_model.settings","title":"settings","text":"<p>Settings for post-processing.</p>"},{"location":"reference/gemseo_calibration/post/data_versus_model/settings/#gemseo_calibration.post.data_versus_model.settings-classes","title":"Classes","text":""},{"location":"reference/gemseo_calibration/post/data_versus_model/settings/#gemseo_calibration.post.data_versus_model.settings.DataVersusModelSettings","title":"DataVersusModelSettings","text":"<p>               Bases: <code>BasePostSettings</code></p> <p>Parameters:</p> <ul> <li> <code>output</code>               (<code>str</code>)           \u2013            <p>The names of the output of interest.</p> </li> </ul>"},{"location":"user_guide/","title":"User guide","text":""},{"location":"user_guide/#user-guide","title":"User guide","text":""}]}